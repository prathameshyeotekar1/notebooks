{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing data in SQL and *pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook covers the basics of recognising and handling the standard encoding of missing data in SQL and *pandas*.\n",
    "\n",
    "We cannot cover the cases where the user has created sentinel values to capture semantic variations in missing data.  In these cases the reasons data is missing usually puts this activity in the data cleansing and harmonisation activities, requiring decisions about appropriate alternative representations, rather than recognising and manipulating missing values.\n",
    "\n",
    "As always, we encourage you to extend these Notebooks as you uncover or refine your techniques for handling specific examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data values in *pandas* are typically represented as `NaN` (not a number) sentinel values, which can be assigned using the numpy library value `np.nan` or `None`. \n",
    "\n",
    "SQL uses `NULL`, and languages such as R tend to use `NA` as the null marker. \n",
    "We can achieve a similar effect by importing the `np.nan` value in as `NA`, so that `NA` appears in place of `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import nan as NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting missing data  into a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you worked through the `03.3 combining data from multiple datasets` Notebook you will already have seen that operations such as the outer joins can generate rows in DataFrames and SQL tables that contain the `NULL` or `NaN` or `None` markers.\n",
    "\n",
    "It is also sometimes useful to be able to insert missing data markers directly into the DataFrame or table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# In pandas we can use an appropriate sentinel value directly in place of an actual value.\n",
    "ss_df = pd.DataFrame( { 'key':['a', 'b', 'c', NA, 'e', 'f'], \n",
    "                        'num':[1, None, 3, 4, np.nan, 5] })\n",
    "# Notice that we've used 3 different representations of the no value \n",
    "# marker - NA, None and np.nan in the above,\n",
    "# but when they're displayed in the pandas Dataframe they're \n",
    "# rendered as NaN, the pandas representation.\n",
    "\n",
    "ss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL allows the NULL marker to be entered in most places where data values can be entered, \n",
    "specifically in the insert into command and update commands.\n",
    "\n",
    "(First we need to setup our Postgres connection, and create a dummy table to work with.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Load in the SQL extensions.\n",
    "%load_ext sql\n",
    "\n",
    "# This is how we connect to a SQL database.\n",
    "%sql postgresql://test:test@localhost:5432/tm351test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS dummy;\n",
    "CREATE TABLE dummy(key INT, name VARCHAR(20), value REAL);\n",
    "INSERT INTO dummy VALUES(NULL,'This',12.1);\n",
    "INSERT INTO dummy VALUES(2, NULL,345.00);\n",
    "INSERT INTO dummy VALUES(3,'The other', NULL);\n",
    "\n",
    "SELECT * FROM dummy;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the returned object is rendered as a DataFrame, so we're seeing the output representation of missing data in the result (for some reason, using the numpy `None`) - but the PostgreSQL database table will have SQL NULL markers in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note here is that the `NaN`, `NA`, `NULL` and `None` etc. can be used whatever the datatype expected - it's a marker for missing data which is effectively typeless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding missing data markers\n",
    "One of the most important issues is working out how to deal with *missing* data, and that starts with finding it.\n",
    "\n",
    "Why do you think using a condition like  `name == NULL`, is unlikely to work?\n",
    "\n",
    "Well, if `NULL` represents missing data - that is a data element that literally has `no value` - how could one `no value` be the same as another `no value`?\n",
    "\n",
    "Both *pandas* and SQL take the same approach - having special conditions tests to identify if missing data markers are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pandas* missing values can be identified using the `isnull()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# We can use the vector-style application of isnull() to test every value in ss_df:\n",
    "ss_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL has a similar conditional expression  `IS NULL` (and its converse `IS NOT NULL`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM dummy\n",
    "WHERE name IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM dummy\n",
    "WHERE name IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing something with missing data\n",
    "\n",
    "*pandas* has several methods for handling DataFrames with missing data.\n",
    "\n",
    "SQL is generally a little poorer in this respect, forcing you to do much of the manipulation yourself.\n",
    "We'll start by looking at the *pandas* methods, then see how we might shape a similar effect over an SQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *pandas*: replacing missing data with a value\n",
    "We can replace a null marker using the `fillna()` method. \n",
    "\n",
    "By default this returns a new object (that is, the original object we apply the method to will not be changed).  To make the original object change we can add the `inplace='True'` qualifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(ss_df.num.fillna(0))\n",
    "# Note that ss hasn't been changed.\n",
    "print(ss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several useful parameters to `fillna()` allowing a range of different filling actions.\n",
    "\n",
    "For more information, see the pandas docs: [pandas.DataFrame.fillna](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *pandas*: deleting rows containing missing data,  various forms\n",
    "We can drop rows containing an NA value *anywhere in the row* using the `dropna()` method.  Once again, this creates a new object unless we add the `inplace=True` qualifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ss_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop just those rows where there is a missing value in a particular column, we can use the `subset` parameter to specify which columns are of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ss_df.dropna(subset=['key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful parameter allows us to just drop rows where *all* the values are missing: `how='all'`.\n",
    "\n",
    "To drop a *column* that is filled with NA values rather than a *row*, use `how='all', axis=1`.\n",
    "\n",
    "For more information, see the pandas docs: [pandas.DataFrame.dropna](http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.DataFrame.dropna.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the SQL used is a SELECT query, we're effectively creating a new table (the result of the SELECT query); to get the equivalent of the 'in place' behaviour we will need to explicitly update or delete the affected rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL:  replacing missing data with a value\n",
    "Basically we use a WHERE clause to identify those rows with NULL in the specified column, and process those appropriately - note that because the WHERE clause will result in only the rows that have NULL being copied to the result, it is then necessary to UNION those with the rows that didn't contain NULL.  (I did say you had a lot more work to do!)  \n",
    "\n",
    "If the change is to create a new object then the COALESCE() function is used - this takes a series of arguments and returns the first one that is not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COALESCE(key, 99999) AS key, \n",
    "       COALESCE(name, 'THIS ONE HAS NO NAME') as name, \n",
    "       COALESCE(value, 0.0) as value\n",
    "FROM dummy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- If coalesce is not available.\n",
    "SELECT key, name, value\n",
    "FROM dummy\n",
    "WHERE value IS NOT NULL\n",
    "UNION\n",
    "SELECT key, name, 0.0\n",
    "FROM dummy\n",
    "WHERE value IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this change 'in place' requires an update statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE dummy\n",
    "SET value = 0.0 \n",
    "WHERE value IS NULL;\n",
    "\n",
    "-- and we can see the change has affected the dummy table\n",
    "SELECT *  FROM dummy;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL: deleting rows containing missing data,  various forms\n",
    "In SQL SELECT you can simply chose the rows you want to keep with increasingly complex condition statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Removing a row with NULL anywhere in it requires each column in the row to be checked \n",
    "-- for the presence of NULL.\n",
    "SELECT * \n",
    "FROM dummy\n",
    "WHERE key IS NOT NULL AND name IS NOT NULL AND value IS NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Remove a row with NULL in a specific column in that row. \n",
    "SELECT * \n",
    "FROM dummy\n",
    "WHERE name IS NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Remove a row with NULL in ALL the columns.\n",
    "SELECT * \n",
    "FROM dummy\n",
    "WHERE NOT( key IS NULL AND name IS NULL AND value IS NULL);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're forced to move to update and delete if we want the 'in place' effect of actually changing the underlying table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Removing a row with NULL anywhere requires each column in the row to be checked.\n",
    "DELETE FROM dummy\n",
    "WHERE key IS NULL OR name IS NULL OR value IS NULL;\n",
    "\n",
    "\n",
    "SELECT * FROM dummy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Oops I needed that - lets get the original table back\n",
    "DROP TABLE IF EXISTS dummy;\n",
    "CREATE TABLE dummy(key INT, name VARCHAR(20), value REAL);\n",
    "INSERT INTO dummy VALUES(NULL,'This',12.1);\n",
    "INSERT INTO dummy VALUES(2, NULL,345.00);\n",
    "INSERT INTO dummy VALUES(3,'The other', NULL);\n",
    "\n",
    "SELECT * FROM dummy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Remove a row with NULL in a specific column in that row.\n",
    "DELETE\n",
    "FROM dummy\n",
    "WHERE name IS NULL;\n",
    "\n",
    "\n",
    "SELECT * FROM dummy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Still needed that but let's add an entirely null row too!\n",
    "DROP TABLE IF EXISTS dummy;\n",
    "CREATE TABLE dummy(key INT, name VARCHAR(20), value REAL);\n",
    "INSERT INTO dummy VALUES(NULL,'This',12.1);\n",
    "INSERT INTO dummy VALUES(2, NULL,345.00);\n",
    "INSERT INTO dummy VALUES(3,'The other', NULL);\n",
    "INSERT INTO dummy VALUES(NULL, NULL, NULL);\n",
    "\n",
    "SELECT * FROM dummy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Remove a row with NULL in ALL the columns.\n",
    "DELETE \n",
    "FROM dummy\n",
    "WHERE key IS NULL AND name IS NULL AND value IS NULL;\n",
    "\n",
    "SELECT * FROM dummy;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL: dropping a column where all rows had NULL in that column\n",
    "SQL would be a bit messy for this.\n",
    "\n",
    "Firstly, to remove an entire column requires the `ALTER TABLE` command with the `DROP < column name >` action.   However, this has no conditional part, so you would need to put this into an SQL conditional statement. \n",
    "\n",
    "Secondly, finding that a column had NULL in every row would require something like counting the number of rows that did not have NULL in that column and seeing if it was zero, but then also checking that you aren't looking at an empty table (one with no rows!).\n",
    "\n",
    "Thirdly, the `IF` condition needed to wrap the condition around the `ALTER TABLE` statement is only available in PostgreSQL functions.\n",
    "\n",
    "And finally, parameterising the required function, so that you could apply this to different columns in different tables, would be ... difficult - the alternative would be to write a specific function for each table and column you might want to apply it to!\n",
    "\n",
    "So it's probably best just to note a quick way to test for an entirely NULL column, and the manual application of the `ALTER TABLE` statement.\n",
    "\n",
    "No promises that this will work in all situations but this might do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Custom table, with one column entirely NULL\n",
    "DROP TABLE IF EXISTS dummy2;\n",
    "CREATE TABLE dummy2(key INT, name VARCHAR(20), value REAL);\n",
    "INSERT INTO dummy2 VALUES(NULL,'This',NULL);\n",
    "INSERT INTO dummy2 VALUES(2, NULL,NULL);\n",
    "INSERT INTO dummy2 VALUES(3,'The other', NULL);\n",
    "INSERT INTO dummy2 VALUES(NULL, NULL, NULL);\n",
    "\n",
    "SELECT * FROM dummy2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- The first part of the condition checks this is not an empty table.\n",
    "--                                         i.e. a table with no rows.\n",
    "-- The second part counts the number of rows where value is not null.\n",
    "--                               If this is 0 then they are all null.\n",
    "-- The 'dummy' outer SELECT simply returns the result of the condition.\n",
    "\n",
    "-- So, if the table is not empty and there are 0 rows where value is not null\n",
    "--        then you want to uncomment the code in the following cell\n",
    "\n",
    "SELECT ( ( (SELECT COUNT(*) FROM dummy2) <> 0)\n",
    " AND\n",
    " ( (SELECT COUNT(*) FROM dummy2 WHERE value IS NOT NULL) = 0 ) );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#%%sql\n",
    "#ALTER TABLE dummy2 DROP COLUMN value;\n",
    "#\n",
    "#SELECT * FROM dummy2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing with missing data elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally - what happens to some standard processing if there is missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- First let us remind ourselves what the dummy2 table looks like.\n",
    "SELECT *\n",
    "FROM dummy2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply some expressions and aggregations using rows and columns with NULL markers in them, and see what happens.\n",
    "Try to predict what you think will happen before looking at the result of running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT (key + 1) AS plusone, name\n",
    "FROM dummy2;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT name || ', add this to every name' AS nameandstring\n",
    "-- Note that the || is the string concatention operator in SQL.\n",
    "FROM dummy2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql -- This one usually catches people out.\n",
    "SELECT COUNT(key) as number_of_keys, COUNT(name) as number_of_names, COUNT(*) as number_of_rows\n",
    "FROM dummy2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT SUM(key) as total_of_keys\n",
    "FROM dummy2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM dummy2\n",
    "ORDER BY key;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as an exercise, why not find out what *pandas* does for the equivalent processing operations when `NAN`s are involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic techniques for identifying missing data (NULL, None, NaN, etc.) are similar in SQL and *pandas*: recognise that the value is missing by testing for it, then use that knowledge to decide what to do to resolve the missing data.\n",
    "\n",
    "There is also a standard set of *pandas* functions to operate on rows or columns containing NULLs; in SQL it's quite a bit harder to get the same effect - but that's because SQL and *pandas* were created for different reasons.  SQL is about the careful management and persistence of data, where restructuring and reshaping is rare; _pandas_ is about data analyse where reshaping and restructuring is vital.\n",
    "\n",
    "The module material talks about using different sentinel values (i.e. special strings like 'not known'). But if you do this you will need to write functions and conditions that identify these values as representing specific conditions in the dataset - and then use these to identify the data as requiring special treatment.  Some specialist libraries already have these kinds of sentinal values and the functions required to operate on them.\n",
    "\n",
    "In all cases, care will be needed to ensure you understand how missing data will be handled in complex expressions, calculations, aggregations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "If you are working through this set of Notebooks as a whole, move on to the Part 4 Notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

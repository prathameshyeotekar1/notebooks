{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation pipeline\n",
    "This Notebook is about getting to know Mongo's accident analysis pipeline. It's presented as a series of exercises that generally replicate queries you've already perfromed on the accidents dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import pymongo\n",
    "import datetime\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Open a connection to the Mongo server, open the accidents database and name the collections of accidents and labels\n",
    "client = pymongo.MongoClient('mongodb://localhost:27351/')\n",
    "\n",
    "db = client.accidents\n",
    "accidents = db.accidents\n",
    "labels = db.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the expanded names of keys and human-readable codes into memory\n",
    "\n",
    "expanded_name = collections.defaultdict(str)\n",
    "for e in labels.find({'expanded': {\"$exists\": True}}):\n",
    "    expanded_name[e['label']] = e['expanded']\n",
    "    \n",
    "label_of = collections.defaultdict(str)\n",
    "for l in labels.find({'codes': {\"$exists\": True}}):\n",
    "    for c in l['codes']:\n",
    "        try:\n",
    "            label_of[l['label'], int(c)] = l['codes'][c]\n",
    "        except ValueError: \n",
    "            label_of[l['label'], c] = l['codes'][c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example\n",
    "First, an example of using the aggregation pipeline to get you started. \n",
    "\n",
    "This pipeline finds all the accidents at 30mph or above, groups them by speed limit, and finds the number of accidents at each speed limit.\n",
    "\n",
    "* `$match` is first and selects the relevant accidents.\n",
    "* `$group` is next and groups the accidents. The `_id` is the value being grouped on. `{'$sum': 1}` is the value assigned to each member of the group, and how those values are combined. This is the idiom for counting members in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Pull out all the accidents at 30mph or above, group by speed, and show totals at each speed.\n",
    "pipeline = [{'$match': {'Speed_limit': {'$gte': 30}}},\n",
    "            {'$group': {'_id': '$Speed_limit',\n",
    "                        'num_accidents': {'$sum': 1}}}]\n",
    "results = list(accidents.aggregate(pipeline))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put the results in a _pandas_ DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index('_id', inplace=True)\n",
    "results_df.index.name = 'speed_limit'\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity note\n",
    "With all the activities below, build up the pipeline in stages. The `$limit` operator is your friend here: it will allow you to see what the pipeline produces without being overwhelmed by thousands of items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 1\n",
    "Find all the accidents at 30mph or above, group them by speed limit and accident severity, and find the number of accidents at each speed limit/severity combination.\n",
    "\n",
    "Hint: If you give multiple keys for a single `$group` operation, it will return one group for each combination of those keys.\n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 2\n",
    "Given the number of accidents at each speed limit/severity combination, create a *pandas* DataFrame to store the results. The DataFrame should have columns of severity (as 'Fatal', 'Serious', 'Slight', in that order) and an index of speed limits (in order).\n",
    "\n",
    "Hint: Convert the result of Activity 1 into a list of dicts, import it into a DataFrame, then use `set_index` and `unstack` to reshape the data.\n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 3\n",
    "Group the accidents by number of vehicles and number of casualties. Find the number of accidents at each vehicle/casualty combination. Store the results in a DataFrame with the number of vehicles as the columns and number of casualties as the index. \n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 4\n",
    "Group the accidents by severity and junction type (`Junction_Detail`). Find the number of accidents at each junction/severity combination. Store the results in a DataFrame with the severities as the columns and junction types as the index. Columns and index should contain the text labels (e.g. Fatal, Serious; Roundabout, Crossroads), not the codes.\n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 5\n",
    "Find the average number of vehicles and casualties for accidents at each speed limit. Replace the `_id` of each speed limit group with the plain `Speed_limit`.\n",
    "\n",
    "Store the results in a DataFrame with the averages as the columns and speed limits as the index. \n",
    "\n",
    "Hint: Use `$group` to find the total vehicles and casualties, then use `$project` to find the averages and rename the ID.\n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 6\n",
    "Find number of casualties for each casualty severity / casualty age band combination. \n",
    "\n",
    "Store the results in a DataFrame with the severities as the columns and age bands as the index. The columns and index should contain the text labels (e.g. 21-25, 46-55; Fatal, Slight), not the codes.\n",
    "\n",
    "Hint: Use `$unwind` to examine each `casualty` sub-document in turn.\n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Activity 7\n",
    "We can use the aggregation pipeline for complex queries. In this exercise, you'll recreate the summary data for finding Spearman's *r* for passenger and driver age bands. \n",
    "\n",
    "Find the number of casualties for each driver age band / passenger age band combination. \n",
    "\n",
    "Be careful that you only count casualty/driver combinations where the casualty and driver are in the same vehicle. Make sure you exclude combinations where either the driver age band or passenger age band is unknown.\n",
    "\n",
    "Store the results in a DataFrame with the driver age band as the columns and passenger age bands as the index. The columns and index should contain the text labels (e.g. 21-25, 46-55), not the codes.\n",
    "\n",
    "Expand the summary results into a list of individual driver/passenger age bands and find Spearman's *r* for these data.\n",
    "\n",
    "Hint: You can't directly `$match` two values in the same document, so use `$project`'s `$eq` to create a field that flags if a driver/casualty combination comes from one vehicle then `$match` on that field.\n",
    "\n",
    "The solution is in the [`15.2solutions`](15.2solutions.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false,
    "collapsed": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Aggregation pipelines allow complex data-processing tasks to be built up from sequences of simple operations. It continues the trend of moving the data processing to be closer to the data. We started by bringing the data into the client machine for processing (in the form of a spreadsheet or DataFrame). Simple database queries allowed us to bring just the data of interest to the client, but we still had to do the processing and summarisation here. Aggregation pipelines allow us to move much more of the processing to the database, meaning we can end up with just the summary data alone. As datasets get larger, this becomes more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## What next?\n",
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to `15.3 Plotting small accidents and roads`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data file formats: file encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways we can explore the encoding used for a file: Unix commands and Python libraries are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# We can run the Unix command line 'file' tool to see if there are any clues about the encoding\n",
    "!file 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python there is a _chardet_ library - unfortunately it hasn't been made to work with Python 3 yet, so we have installed a Linux library on the virtual machine, `chardet`, that does the same. `chardet` has a command-line tool `chardetect` that examines file encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unix `whereis` command will find the executable version of the named code, and report the directory location for the file.  In this case we want to know where the `chardetect` code lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# The chardet library has a simple command-line tool called 'chardetect' that \n",
    "#    tries to sniff file encodings:\n",
    "!whereis chardetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know where it lives, we can call it directly (this tool sometimes takes a while to complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# We can call this tool with a filename to see if it can detect the encoding for us:\n",
    "!/usr/local/bin/chardetect 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the confidence interval is reported. `chardetect` may not always get it right, but you do get a measure of how sure it is about the encoding it reports.  (Note: `window-1252`, which is reported when I ran the chardetect on the `Published Format - Nov 2013` file is also known as `ISO-8859-2`, this may be reported as the file encoding in place of the `windows-1252` above.)\n",
    "\n",
    "It is always worth quickly looking over the dataset (for example, using the command-line `head` command) to see what looks reasonable (though of course a single rogue character in the dataset may cause problems when it comes to reading the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# If you want a quick look at the file, 'head filename' will display the first \n",
    "# 10 lines of the file (if it can).\n",
    "!head 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a reasonable guess at the file encoding, we can use that to open this CSV file in *pandas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the file as a .csv file with the encoding given...\n",
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv', encoding = 'windows-1252')\n",
    "# ... and show us the first three rows:\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we don't specify the encoding, *pandas* can't decode the file content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Exercise\n",
    "What happens if you try to read the file `data/carparks.kml` using the Python `open()` file function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "with open('data/CarParks.kml') as f:\n",
    "    kmlcontent = f.read()\n",
    "kmlcontent[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "The `open()` command can take a parameter `encoding='string'` that allows you to specify the encoding of the file to be opened and read. \n",
    "\n",
    "In the next two cells use `chardetect` to detect the file encoding and then see if you can open the file using this encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use chardetect to detect the file encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Add the appropriate file encoding to the open statement.\n",
    "with open('data/CarParks.kml', encoding='YOUR_ENCODING_HERE') as f:\n",
    "    kmlcontent = f.read()\n",
    "kmlcontent[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activityAns"
   },
   "source": [
    "### Sample solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample Solution\n",
    "# Use chardetect to detect the file encoding.\n",
    "!/usr/local/bin/chardetect 'data/CarParks.kml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample solution\n",
    "# Add the appropriate file encoding to the open statement.\n",
    "with open('data/CarParks.kml', encoding='utf-8') as f:\n",
    "    kmlcontent = f.read()\n",
    "kmlcontent[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "Does the first line of the file also give you any clues as to what the encoding may be?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!head 'data/CarParks.kml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity",
    "code_folding": [
     0
    ]
   },
   "source": [
    "This is quite common, with many standard file formats using the first few bytes of the file to carry details of the file's own encoding. (Another reason a quick look at the first few lines of a file can be rewarding!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3, strings are represented using Unicode characters. We can inspect the Unicode values of individual characters using methods from the `unicodedata` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "chars = \"abc 123 é © 草\"\n",
    "for char in chars:\n",
    "    # Print the character, followed by its Unicode value in hexadecimal, then decimal, \n",
    "    #     followed by its Unicode name.\n",
    "    print(char,'%04x' % ord(char),'%d' % ord(char), unicodedata.name(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character encodings, such as ASCII or UTF-8, also define a sequence of integer values that map onto individual characters.\n",
    "\n",
    "As an encoding that is expansive enough to define characters and symbols from across a wide range of languages, Unicode is expensive to use if we know we only want to encode a small range of characters, such as the characters included in the ACSII scheme: A-Z, a-z, 0-9 and a few punctuation characters. ASCII codes are 7-bits wide, compared to the 32-bit representation used by Unicode (UTF-32). If all you want to do is store English text strings, with no accented characters, it makes sense in terms of mimimising memory requirements to encode the characters using the leaner ASCII coding scheme.\n",
    "\n",
    "We can look at the byte-encoded values of a string according to a specified character encoding using the `str.encode()` method (the default character encoding is UTF-8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(chars.encode(),'\\n',chars.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The 'b' at the start of each of the quoted sequences in the output from the above cell indicates that this is a bytestream, not a string object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# What happens if we try to encode characters that are out of range of the character encoding?\n",
    "# Here we try to encode our 'chars' string using ascii encoding.\n",
    "print(chars.encode('ascii') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding fails when it encounters the é character, which is not representable by the ASCII encoding scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  operation complementary to encoding strings into byte strings or byte streams is to decode byte streams to Unicode character strings. (Once again, the default encoding is UTF-8.)\n",
    "\n",
    "Byte strings can be decoded using the `bytes.decode()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bytes.decode(b'\\xe8\\x8d\\x89')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or declaring a string as a bytestream and then decoding it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "b'\\xe8\\x8e\\x88'.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook you've seen how to:\n",
    "1. detect the encoding used for a file \n",
    "2. use the encoding to open files correctly\n",
    "3. use the `unicodedata` package to encode and decode bytestreams using a range of encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to look at `02.2.1 Data file formats - CSV`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

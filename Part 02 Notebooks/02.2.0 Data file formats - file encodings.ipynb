{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data file formats: file encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways we can explore the encoding used for a file: Unix commands and Python libraries are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv: ASCII text, with CRLF line terminators\r\n"
     ]
    }
   ],
   "source": [
    "# We can run the Unix command line 'file' tool to see if there are any clues about the encoding\n",
    "!file 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python there is a _chardet_ library - unfortunately it hasn't been made to work with Python 3 yet, so we have installed a Linux library on the virtual machine, `chardet`, that does the same. `chardet` has a command-line tool `chardetect` that examines file encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unix `whereis` command will find the executable version of the named code, and report the directory location for the file.  In this case we want to know where the `chardetect` code lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chardetect: /usr/local/bin/chardetect\r\n"
     ]
    }
   ],
   "source": [
    "# The chardet library has a simple command-line tool called 'chardetect' that \n",
    "#    tries to sniff file encodings:\n",
    "!whereis chardetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know where it lives, we can call it directly (this tool sometimes takes a while to complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv: windows-1252 with confidence 0.73\r\n"
     ]
    }
   ],
   "source": [
    "# We can call this tool with a filename to see if it can detect the encoding for us:\n",
    "!/usr/local/bin/chardetect 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the confidence interval is reported. `chardetect` may not always get it right, but you do get a measure of how sure it is about the encoding it reports.  (Note: `window-1252`, which is reported when I ran the chardetect on the `Published Format - Nov 2013` file is also known as `ISO-8859-2`, this may be reported as the file encoding in place of the `windows-1252` above.)\n",
    "\n",
    "It is always worth quickly looking over the dataset (for example, using the command-line `head` command) to see what looks reasonable (though of course a single rogue character in the dataset may cause problems when it comes to reading the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital or Revenue,Directorate,Transaction Number,Date,Service Area,Expenses Type,Amount,Supplier Name\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105636098,13.11.2013,Public Libraries Central,Marketing Costs,200.00,REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105635705,08.11.2013,Drug Misuse - Adults,Charges from Independent Providers,120.00,REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Childrens Services,5105637261,20.11.2013,Thompson House Tuition Centre (PRU),Professional Services,240.00,* M BOWDERY T/A SPOTLIGHT BOUTIQUE\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105637069,27.11.2013,Safeguarding Adults,Professional Services,\"5,285.00\",REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105637605,22.11.2013,Leaseholds by LA,Accommodation Costs - Leaseholder Payments,695.89,REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105637605,22.11.2013,Leaseholds by LA,Accommodation Costs - Leaseholder Payments,695.89,REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105637605,22.11.2013,Leaseholds by LA,Accommodation Costs - Leaseholder Payments,695.89,REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105637605,22.11.2013,Leaseholds by LA,Accommodation Costs - Leaseholder Payments,695.89,REDACTED PERSONAL DATA\r",
      "\r\n",
      "Revenue,Community Wellbeing & Social Care,5105637605,22.11.2013,Leaseholds by LA,Accommodation Costs - Leaseholder Payments,695.89,REDACTED PERSONAL DATA\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# If you want a quick look at the file, 'head filename' will display the first \n",
    "# 10 lines of the file (if it can).\n",
    "!head 'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a reasonable guess at the file encoding, we can use that to open this CSV file in *pandas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Capital or Revenue</th>\n",
       "      <th>Directorate</th>\n",
       "      <th>Transaction Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Service Area</th>\n",
       "      <th>Expenses Type</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Supplier Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Community Wellbeing &amp; Social Care</td>\n",
       "      <td>5105636098</td>\n",
       "      <td>13.11.2013</td>\n",
       "      <td>Public Libraries Central</td>\n",
       "      <td>Marketing Costs</td>\n",
       "      <td>200.00</td>\n",
       "      <td>REDACTED PERSONAL DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Community Wellbeing &amp; Social Care</td>\n",
       "      <td>5105635705</td>\n",
       "      <td>08.11.2013</td>\n",
       "      <td>Drug Misuse - Adults</td>\n",
       "      <td>Charges from Independent Providers</td>\n",
       "      <td>120.00</td>\n",
       "      <td>REDACTED PERSONAL DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revenue</td>\n",
       "      <td>Childrens Services</td>\n",
       "      <td>5105637261</td>\n",
       "      <td>20.11.2013</td>\n",
       "      <td>Thompson House Tuition Centre (PRU)</td>\n",
       "      <td>Professional Services</td>\n",
       "      <td>240.00</td>\n",
       "      <td>* M BOWDERY T/A SPOTLIGHT BOUTIQUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Capital or Revenue                        Directorate Transaction Number  \\\n",
       "0            Revenue  Community Wellbeing & Social Care         5105636098   \n",
       "1            Revenue  Community Wellbeing & Social Care         5105635705   \n",
       "2            Revenue                 Childrens Services         5105637261   \n",
       "\n",
       "         Date                         Service Area  \\\n",
       "0  13.11.2013             Public Libraries Central   \n",
       "1  08.11.2013                 Drug Misuse - Adults   \n",
       "2  20.11.2013  Thompson House Tuition Centre (PRU)   \n",
       "\n",
       "                        Expenses Type  Amount  \\\n",
       "0                     Marketing Costs  200.00   \n",
       "1  Charges from Independent Providers  120.00   \n",
       "2               Professional Services  240.00   \n",
       "\n",
       "                        Supplier Name  \n",
       "0              REDACTED PERSONAL DATA  \n",
       "1              REDACTED PERSONAL DATA  \n",
       "2  * M BOWDERY T/A SPOTLIGHT BOUTIQUE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the file as a .csv file with the encoding given...\n",
    "df = pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv', encoding = 'windows-1252')\n",
    "# ... and show us the first three rows:\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we don't specify the encoding, *pandas* can't decode the file content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 6: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a31444572057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m _parser_defaults = {\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skip_footer not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1197\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1198\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7988)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:8244)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:9261)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._convert_column_data (pandas/parser.c:10654)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._convert_tokens (pandas/parser.c:11540)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._convert_with_dtype (pandas/parser.c:12976)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._string_convert (pandas/parser.c:13222)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser._string_box_utf8 (pandas/parser.c:18598)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 6: invalid start byte"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('data/iwCouncilSpending/PUBLISHED FORMAT - NOV 2013.csv')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "### Exercise\n",
    "What happens if you try to read the file `data/carparks.kml` using the Python `open()` file function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 42785: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3dec8a659594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/CarParks.kml'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mkmlcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mkmlcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/encodings/ascii.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascii_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 42785: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "with open('data/CarParks.kml') as f:\n",
    "    kmlcontent = f.read()\n",
    "kmlcontent[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "The `open()` command can take a parameter `encoding='string'` that allows you to specify the encoding of the file to be opened and read. \n",
    "\n",
    "In the next two cells use `chardetect` to detect the file encoding and then see if you can open the file using this encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/CarParks.kml: utf-8 with confidence 0.99\r\n"
     ]
    }
   ],
   "source": [
    "!chardetect 'data/CarParks.kml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<kml xmlns=\"http://earth.google.com/kml/2.2\">\\n<Document>\\n  <n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the appropriate file encoding to the open statement.\n",
    "with open('data/CarParks.kml', encoding='utf-8') as f:\n",
    "    kmlcontent = f.read()\n",
    "kmlcontent[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activityAns"
   },
   "source": [
    "### Sample solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "activity": "activity",
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/CarParks.kml: utf-8 with confidence 0.99\r\n"
     ]
    }
   ],
   "source": [
    "# Sample Solution\n",
    "# Use chardetect to detect the file encoding.\n",
    "!/usr/local/bin/chardetect 'data/CarParks.kml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<kml xmlns=\"http://earth.google.com/kml/2.2\">\\n<Document>\\n  <n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample solution\n",
    "# Add the appropriate file encoding to the open statement.\n",
    "with open('data/CarParks.kml', encoding='utf-8') as f:\n",
    "    kmlcontent = f.read()\n",
    "kmlcontent[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity"
   },
   "source": [
    "Does the first line of the file also give you any clues as to what the encoding may be?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "activity": "activity",
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n",
      "<kml xmlns=\"http://earth.google.com/kml/2.2\">\r\n",
      "<Document>\r\n",
      "  <name>Car Parks</name>\r\n",
      "  <description><![CDATA[View all the Island car parks managed by the local authority]]></description>\r\n",
      "  <Style id=\"style9\">\r\n",
      "    <IconStyle>\r\n",
      "      <Icon>\r\n",
      "        <href>http://www.iwight.com/images/pins/longstay.png</href>\r\n",
      "      </Icon>\r\n"
     ]
    }
   ],
   "source": [
    "!head 'data/CarParks.kml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": "activity",
    "code_folding": [
     0
    ]
   },
   "source": [
    "This is quite common, with many standard file formats using the first few bytes of the file to carry details of the file's own encoding. (Another reason a quick look at the first few lines of a file can be rewarding!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3, strings are represented using Unicode characters. We can inspect the Unicode values of individual characters using methods from the `unicodedata` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0061 97 LATIN SMALL LETTER A\n",
      "b 0062 98 LATIN SMALL LETTER B\n",
      "c 0063 99 LATIN SMALL LETTER C\n",
      "  0020 32 SPACE\n",
      "1 0031 49 DIGIT ONE\n",
      "2 0032 50 DIGIT TWO\n",
      "3 0033 51 DIGIT THREE\n",
      "  0020 32 SPACE\n",
      "é 00e9 233 LATIN SMALL LETTER E WITH ACUTE\n",
      "  0020 32 SPACE\n",
      "© 00a9 169 COPYRIGHT SIGN\n",
      "  0020 32 SPACE\n",
      "草 8349 33609 CJK UNIFIED IDEOGRAPH-8349\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "chars = \"abc 123 é © 草\"\n",
    "for char in chars:\n",
    "    # Print the character, followed by its Unicode value in hexadecimal, then decimal, \n",
    "    #     followed by its Unicode name.\n",
    "    print(char,'%04x' % ord(char),'%d' % ord(char), unicodedata.name(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character encodings, such as ASCII or UTF-8, also define a sequence of integer values that map onto individual characters.\n",
    "\n",
    "As an encoding that is expansive enough to define characters and symbols from across a wide range of languages, Unicode is expensive to use if we know we only want to encode a small range of characters, such as the characters included in the ACSII scheme: A-Z, a-z, 0-9 and a few punctuation characters. ASCII codes are 7-bits wide, compared to the 32-bit representation used by Unicode (UTF-32). If all you want to do is store English text strings, with no accented characters, it makes sense in terms of mimimising memory requirements to encode the characters using the leaner ASCII coding scheme.\n",
    "\n",
    "We can look at the byte-encoded values of a string according to a specified character encoding using the `str.encode()` method (the default character encoding is UTF-8):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or declaring a string as a bytestream and then decoding it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'abc 123 \\xc3\\xa9 \\xc2\\xa9 \\xe8\\x8d\\x89' \n",
      " b'abc 123 \\xc3\\xa9 \\xc2\\xa9 \\xe8\\x8d\\x89'\n"
     ]
    }
   ],
   "source": [
    "print(chars.encode(),'\\n',chars.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The 'b' at the start of each of the quoted sequences in the output from the above cell indicates that this is a bytestream, not a string object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  operation complementary to encoding strings into byte strings or byte streams is to decode byte streams to Unicode character strings. (Once again, the default encoding is UTF-8.)\n",
    "\n",
    "Byte strings can be decoded using the `bytes.decode()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\xe9' in position 8: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-48eb93542c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# What happens if we try to encode characters that are out of range of the character encoding?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Here we try to encode our 'chars' string using ascii encoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xe9' in position 8: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# What happens if we try to encode characters that are out of range of the character encoding?\n",
    "# Here we try to encode our 'chars' string using ascii encoding.\n",
    "print(chars.encode('ascii') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding fails when it encounters the é character, which is not representable by the ASCII encoding scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'草'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes.decode(b'\\xe8\\x8d\\x89')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'莈'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'\\xe8\\x8e\\x88'.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook you've seen how to:\n",
    "1. detect the encoding used for a file \n",
    "2. use the encoding to open files correctly\n",
    "3. use the `unicodedata` package to encode and decode bytestreams using a range of encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to look at `02.2.1 Data file formats - CSV`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

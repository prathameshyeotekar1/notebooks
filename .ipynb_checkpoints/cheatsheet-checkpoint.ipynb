{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### BASIC SERIES AND DATAFRAMES###\n",
    "#create a new dataframe in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "courseData = { 'courseCode': ['TM351', 'TU100', 'M269'],\n",
    "               'points':[30, 60, 30],\n",
    "               'level':['3', '1', '2']\n",
    "             }\n",
    "course_df = DataFrame(courseData)\n",
    "course_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Adding a new column:\n",
    "course_df['Degree Percentage'] = ((course_df['points'] / 360) * 100)\n",
    "course_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#create a new dataframe using named columns\n",
    "courseColumns = ['courseCode', 'difficulty']\n",
    "courseData2 = { 'courseCode':['TM351', 'TU100', 'M269'],\n",
    "               'difficulty':['easy', 'medium', 'insane']\n",
    "             }\n",
    "course_df2 = DataFrame(data=courseData2, columns=courseColumns)\n",
    "course_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading data from an excel spreadsheet into a dataframe\n",
    "licences_df = pd.read_excel('data/MKxx DRL0102 Driving-licence-data-Mar15.xls',\n",
    "                            skiprows=27)[:(54-28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reading data from a csv file into a dataframe\n",
    "#See some nice examples here : \n",
    "#http://chrisalbon.com/python/pandas_dataframe_importing_csv.html\n",
    "df = pd.read_csv('../data/example.csv', na_values=sentinels, skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#projecting columns (note the double brackets)\n",
    "course_df[['courseCode', 'level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#selecting rows based on column value\n",
    "course_df[(course_df['courseCode'] == 'TM351' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#selecting row based on index number\n",
    "course_df.ix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#selecting a single cell can be achieved by using a combination of selection and projection\n",
    "#e.g. to select points for TM351\n",
    "course_df[course_df['courseCode']=='TM351']['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#or\n",
    "course_df['points'].ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "attempt_counts_df.rename(columns={'Personal Identifier':'Student', 'Surname':'Quiz Attempts'}, inplace = True)\n",
    "#or\n",
    "quizzes_by_hour_and_state.columns = ['Hour started', 'Finished', 'In progress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#examining dataframe types, and casting\n",
    "course_df[ ['level', 'points'] ] = course_df[ ['level', 'points'] ].astype(float)\n",
    "course_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Adding 2 dataframes together (add rows)\n",
    "#by default, all columns are added (outer join). To add only common columns use join='inner' option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "courses_comb_df = pd.concat([course_df, course_df])\n",
    "courses_comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#merging 2 dataframes together (add columns)\n",
    "#by default, rows are only added if they both contain the key column (inner join). To not lose any columns \n",
    "#use how='left', how='right' or how='full'\n",
    "courses_comb_df = pd.merge(course_df, course_df2, on=['courseCode'])\n",
    "courses_comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### DATA PREPARATION AND CLEANSING###\n",
    "#dealing with missing values\n",
    "dirty_df = DataFrame(\n",
    "    {'laptop': ['macbook pro', 'dell xps', 'microsoft surface pro'],\n",
    "     'price': [1600, 1400, None]} #nb, None, NA and np.nan all work\n",
    ")\n",
    "#check which cells are null\n",
    "dirty_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#replace null values with desired value\n",
    "dirty_df.price.fillna(0, inplace='true')\n",
    "dirty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#replace null values for specific columns:\n",
    "\n",
    "answer_columns = list(icma_df) #get list of all columns\n",
    "answer_columns = answer_columns[12:]  #discard first 12 columns \n",
    "icma_df[answer_columns] = icma_df[answer_columns].fillna(0) #fill just desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#drop rows where specified column contains null values\n",
    "clean_df = dirty_df.dropna(subset=['price'])\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Simple string replace / regex pattern matching and replacing\n",
    "samples = pd.DataFrame({'test_string' : ['aba', \n",
    "                                         'abcababcabca', \n",
    "                                         'adfddfda', \n",
    "                                         'The Cat sat on the Mat',\n",
    "                                         'The Dog sat on the Cat',\n",
    "                                         'The Elephant sat on the Dog']})\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#simple string replace. This works, but is pretty basic as cell contents\n",
    "#has to be a full match\n",
    "samples.replace({'test_string' : 'aba'}, 'XXXXXXXXX', inplace=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Find and replace using regex expression\n",
    "#Use this great tool for checking regex expressions:\n",
    "#https://regex101.com/\n",
    "samples.replace({'test_string' : 'a[bd][a-z]+'}, 'XXX', regex=True, inplace=True)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#### DESCRIPTIVE STATISTICS###\n",
    "#count occurence of one value with respect to another using crosstabs method\n",
    "#laptop_df = DataFrame({\n",
    "#    'Name':['Apple MacBook Pro 15 inch','Apple MacBook Pro 13 inch','Microsoft Surface Book', 'ASUS ZenBook Pro', 'Dell XPS 15 Notebook'],\n",
    "#    'Brand':['Apple','Apple','Microsoft','ASUS','Dell'],\n",
    "#    'Memory (GB)':[16,8,16,16,16],\n",
    "#    'Operating System':['Mac OS X El Capitan','Mac OS X El Capitan','Windows 10 Pro','Windows 10 (64 bit)','Windows 10 (64 bit)'],\n",
    "#    'Processor Model':['i7-4770HQ','i5','i7?','i7?','i7-6700HQ'],\n",
    "#    'Processor Generation':[4,5,6,6,6],\n",
    "#    'Screen sizeÂ (inches)':[15.4,13.3,13.5,15.6,15.6],\n",
    "#    'Price':[1599,1149.99,2249,1499.95,1399.95],\n",
    "#    'Guarantee (years)':[3,2,2,2,3]\n",
    "#})\n",
    "columns=['Division', 'Quarter','Sales']\n",
    "finances_df = DataFrame({\n",
    "'Division':['South','East','West','West','South','West','South','South','East','West'],\n",
    "'Quarter':['q1-2016','q1-2016','q1-2016','q1-2016','q2-2016','q2-2016','q3-2016','q3-2016','q3-2016','q3-2016'],\n",
    "'Sales':[800,1600,700,2100,900,2800,750,2000,600,400]\n",
    "}, columns=columns)\n",
    "finances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Get the size of the x and y dimensions \n",
    "finances_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#summarize one column with respect to another using crosstab \n",
    "#(e.g. summarise Division with respect to Quarter)\n",
    "# use margins = 'true' to include totals column and row\n",
    "pd.crosstab(finances_df['Division'], finances_df['Quarter'], margins='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#use a simple pivot table to group by 1 column, and count another\n",
    "attempt_counts_df = pd.pivot_table(icma_df, index=['Personal Identifier'],values=[\"Surname\"],aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#find the index of the row with the max count\n",
    "most_quiz_attempts_pi = attempt_counts_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#use a pivot table to group by a column and sum another column\n",
    "import numpy as np # we need this for the aggregate functions\n",
    "finances_df.pivot_table(index=['Division'], aggfunc=np.sum) #gives sum across each division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#gives sum accross each Quarter, for each Division (hierarchy of columns)\n",
    "finances_df.pivot_table(index=['Division','Quarter'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#we can also have more than one aggregate function column, as follows\n",
    "finances_df.pivot_table(index=['Division','Quarter'], aggfunc=[np.sum,np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Using the describe function on series and dataframes\n",
    "aseries = pd.Series([1,2,9,6,5,6,8,6,2])\n",
    "aseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "adf = pd.DataFrame({'size':[1, 2, 4, 5, 1, 4, 2, 8], \n",
    "                    'cost':[30, 42, 24, 75, 82, 50, 20, 34]})\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#use describe on a series to get count, mean, std etc.\n",
    "aseries.describe() #we can also call mode(), median(), mean() etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#use describe on a dataframe to count, mean etc. plus percentiles e.g 25% of values are less than 28.5, 50% less than 38 etc.\n",
    "adf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Using aggregate functions on series e.g. sum, mean, median, mode, min, max etc.\n",
    "aseries.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Using aggregate functions on dataframes e.g. sum, mean, min, max etc.\n",
    "#use axis=0 to apply function to columns, axis=1 to apply to rows\n",
    "#use skipna=True flag to skip non-numerics\n",
    "adf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Use additive functions like cumulative sum, culumative max on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "adf.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#finding the min / max value in a series\n",
    "#, or row or column with the min / max value in a dataframe\n",
    "aseries.idxmin() #returns the (zero based) index of the min value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "adf.idxmax(axis=0) #returns the row index for the max value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Plotting dataframes using the plot function\n",
    "PostData = pd.DataFrame( [('Box', 3, 10, 10, 3), ('Case', 8, 10,17,5), \n",
    "                          ('Drawer',12,23,32,12), ('Shelf', 52,23,46,17), \n",
    "                          ('Cabinet',7,10,27,9), ('Rack', 47,23,30,10), \n",
    "                          ('Bag',3,30,147,59), ('Hanger',30,23,62,23), \n",
    "                          ('Bracket', 3,30,92.5,37) ], \n",
    "                        columns=['itemname','price','postcost','weight','size'])\n",
    "PostData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "PostData.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#some nice options here, including chart type (line, bar, bar-horizontal and scatter plots),\n",
    "# x and y limits, colour, x and y labels\n",
    "PostData.plot.bar(x='itemname', y='weight', title=\"My chart title\", \n",
    "                      ylim=(0,max(PostData.weight)+10),\n",
    "                      color='green')\n",
    "plt.xlabel('Item Name')\n",
    "plt.ylabel('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "PostData.plot(x='weight', y='postcost', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Reshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#transpose rows / columns\n",
    "df = pd.DataFrame(np.arange(6).reshape(3,2), columns=['a','b'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#make long table into wide table\n",
    "directorates = ['Community Wellbeing & Social Care',\n",
    "                'Childrens Services',\n",
    "                'Economy & Environment',\n",
    "                'Resources',\n",
    "                'Corporate']\n",
    "expensetypes = ['Accommodation Costs',\n",
    "                'Payment to Private Contractors',\n",
    "                'Operational Equipment',\n",
    "                'Professional Services']\n",
    "import itertools\n",
    "a = list(itertools.product(directorates, expensetypes))\n",
    "unzipa = [t for t in zip(*a)]\n",
    "df_long = pd.DataFrame({'directorates':unzipa[0],\n",
    "                        'expense types':unzipa[1],\n",
    "                        'total':np.random.randint(0,20000,len(directorates)*len(expensetypes))\n",
    "                      })\n",
    "df_long[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#To make this 'long' table 'wide', we can use pivot:\n",
    "df_wide = df_long.pivot('directorates', 'expense types', 'total')\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#To unstack the entire table into a long table again:\n",
    "df_wide.stack() #nb we can reverse this again with unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#or just unstack a specific column using melt\n",
    "simple_melt = pd.melt(df_wide, id_vars=['directorates'], value_vars=expensetypes)\n",
    "simple_melt\n",
    "#NEED TO WORK OUT WHY THIS EXAMPLE ISN'T WORKING PROPERLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
